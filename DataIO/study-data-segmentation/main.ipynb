{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook covers uploading semantic segmentations a study level task. \n",
    "\n",
    "Within `NIFTI_images` are 7 MRI studies, each containing 4 different series each - flair, t1, t1ce, t2. Each series has a corresponding semantic segmentation NIfTI map within `NIFTI_segmentations`.\n",
    "\n",
    "The following code will create the correct mapping `JSON` files required to upload 7 study level tasks with pre-segmentations for each series. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mapping file\n",
    "Because we are working with semantic segmentation annotations, each category maps directly to a single class ID. The following object maps between the class ID within your NIfTI files, and the category name of your RedBrick AI taxonomy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"1\": \"necrosis\",\n",
    "    \"2\": \"edema\",\n",
    "    \"3\": \"non-enhancing tumor\",\n",
    "    \"4\": \"enhancing tumor\"\n",
    "}\n",
    "with open(\"mapping.json\", \"w+\") as file:\n",
    "    json.dump(mapping, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your items file\n",
    "Next, we must create an items file that will upload your studies and corresponding segmentation maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"brain-brats-study\"\n",
    "image_dir = \"NIFTI_images\"\n",
    "seg_dir = \"NIFTI_segmentations\"\n",
    "items = []\n",
    "for study in os.listdir(os.path.join(root, image_dir)):\n",
    "    if not os.path.isdir(os.path.join(root, image_dir, study)):\n",
    "        continue\n",
    "    \n",
    "    series = os.listdir(os.path.join(root, image_dir, study))\n",
    "    items += [\n",
    "        {\n",
    "            \"name\": study,\n",
    "            \"items\": [\n",
    "                os.path.join(root, image_dir, study, file) for file in series\n",
    "            ],\n",
    "            \"segmentations\": [\n",
    "                os.path.join(root, seg_dir, study, file[:-7] + \"_seg.nii.gz\") for file in series\n",
    "            ]\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"items.json\", \"w+\") as file:\n",
    "    json.dump(items, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8eaac75e0f6bac40e1bd8a4a6235d6e3e9ecfdd9d25e764a66c3f23bade002b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
