{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook covers uploading semantic segmentations a study level task. \n",
    "\n",
    "Within `NIFTI_images` are 7 MRI studies, each containing 4 different series each - flair, t1, t1ce, t2. Each series has a corresponding semantic segmentation NIfTI map within `NIFTI_segmentations`.\n",
    "\n",
    "The following code will create the correct mapping `JSON` files required to upload 7 study level tasks with pre-segmentations for each series. \n",
    "\n",
    "> ‚ùï Please have a look at the reference formats found in `format.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mapping file\n",
    "Because we are working with semantic segmentation annotations, each category maps directly to a single class ID. The following object maps between the class ID within your NIfTI files, and the category name of your RedBrick AI taxonomy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"1\": \"necrosis\",\n",
    "    \"2\": \"edema\",\n",
    "    \"3\": \"non-enhancing tumor\",\n",
    "    \"4\": \"enhancing tumor\"\n",
    "}\n",
    "with open(\"mapping.json\", \"w+\") as file:\n",
    "    json.dump(mapping, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your items file\n",
    "Next, we must create an items file that will upload your studies and corresponding segmentation maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"brain-brats-study\"\n",
    "image_dir = \"NIFTI_images\"\n",
    "seg_dir = \"NIFTI_segmentations\"\n",
    "items = []\n",
    "for study in os.listdir(os.path.join(root, image_dir)):\n",
    "    if not os.path.isdir(os.path.join(root, image_dir, study)):\n",
    "        continue\n",
    "    \n",
    "    series = os.listdir(os.path.join(root, image_dir, study))\n",
    "    items += [\n",
    "        {\n",
    "            \"name\": study,\n",
    "            \"items\": [\n",
    "                os.path.join(root, image_dir, study, file) for file in series\n",
    "            ],\n",
    "            \"segmentations\": [\n",
    "                os.path.join(root, seg_dir, study, file[:-7] + \"_seg.nii.gz\") for file in series\n",
    "            ]\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"items.json\", \"w+\") as file:\n",
    "    json.dump(items, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data using CLI\n",
    "Once you have created the mapping, and items JSON files, you can upload the data using the RedBrick AI CLI. First perform the standard set up: \n",
    "\n",
    "```console\n",
    "$ pip install -U redbrick-sdk\n",
    "$ redbrick config // Fill out org_id, api_key etc.\n",
    "$ redbrick clone project_id // or use redbrick init to create a new project\n",
    "$ cd project_directory\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally stored data\n",
    "If your data is stored locally, the process is straightforward:\n",
    "\n",
    "```console\n",
    "$ redbrick upload --json items.json --segment-map mapping.json\n",
    "```\n",
    "This command prompts the CLI to upload the locally stored data/segmentations in `items.json`, and the `mapping.json` file gives information on how to map class ID's to category names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud data, local annotations\n",
    "In the case your data is stored in the cloud e.g. AWS s3, and annotations are stored locally, you need to do the following:\n",
    "\n",
    "```console\n",
    "$ redbrick upload --storage <storage_id> --json items.json --segment-map mapping.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `--storage` flag will prompt RedBrick AI to fetch only the image data from `items.json` from your cloud bucket (identified by `<storage_id>`, you can find your `<storage_id>` withing the Storage Tab on the RedBrick AI platform). With this command, the segmentations will be uploaded from your local machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud data, and cloud annotations\n",
    "In the case both your annotations and data are stored in the cloud, e.g. AWS s3, you need to first set your projects annotation storage location to your clod bucket. This is a project wide setting, and when this is set to your cloud bucket, RedBrick will read and write annotations directly from your bucket. Note, this requires your bucket to be configured to have `GET` and `PUT` object access.\n",
    "\n",
    "```console\n",
    "$ redbrick info --set labelstorage\n",
    "> Storage ID: <storage_id>\n",
    "> Path prefix: path/to/label/directory\n",
    "```\n",
    "\n",
    "Once you've set your labelstorage method to your cloud bucket, you can upload the data as follows: \n",
    "```console\n",
    "$ redbrick upload --storage <storage_id> --json items.json --segment-map mapping.json\n",
    "```\n",
    "This command will prompt RedBrick to look for your data at the paths defined in `items.json` within your bucket (defined by `<storage_id>`), and it will look for your annotation files within the bucket, and path you set in the previous command. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8eaac75e0f6bac40e1bd8a4a6235d6e3e9ecfdd9d25e764a66c3f23bade002b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
